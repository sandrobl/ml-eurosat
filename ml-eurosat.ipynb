{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FalwJeqyvs79"
      },
      "source": [
        "###  Coding Challenge - Getting Started\n",
        "\n",
        "<img align=\"right\" style=\"max-width: 200px; height: auto\" src=\"https://github.com/sandrobl/ml-eurosat/blob/main/hsg_logo.png?raw=1\">\n",
        "<img align=\"center\" style=\"max-width: 300px; height: auto\" src=\"https://github.com/sandrobl/ml-eurosat/blob/main/sentinel2.jpg?raw=1\">\n",
        "\n",
        "8,860,1.00 MCS Machine Learning, Spring Term 2025, University of St.Gallen (HSG)\n",
        "\n",
        "The lab environment of the **8,860,1.00 Machine Learning** course is powered by Jupyter Notebooks (https://jupyter.org), which allows one to perform a great deal of data analysis and statistical validation. In this first lab, we want to touch on the basic concepts and techniques of such notebooks. Furthermore, its capabilities will be demonstrated based on a few simple and introductory examples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdgXTGCEvs7-"
      },
      "source": [
        "### Objectives:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUQB7QtBvs7-"
      },
      "source": [
        "With the help of this notebook you should be able to:\n",
        "    \n",
        "> 1. Understand the basic funcitonality of the rasterio framework\n",
        "> 2. Apply rasterio to load GTiff data\n",
        "> 3. Visualize multi-band satellite imagery\n",
        "> 4. Perform basic band arithmetic to compute the normalized difference vegetation index (NDVI)\n",
        "> 5. Load and display samples from the challenge testset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AhbmTLQvs7_"
      },
      "source": [
        "## 2. Setup of the Jupyter Notebook Environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrBoV_N6vs7_"
      },
      "source": [
        "Similar to the previous labs, we need to import a couple of Python libraries that allow for data analysis and data visualization. We will use `os` and `glob` to collect the filepaths for the data samples, `numpy` for array operations, `matplotlib` to display images, and `rasterio` to handle raster data. You can find the documentation of the `rasterio` library with an overview of its functionality [here](https://rasterio.readthedocs.io)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CEl9pSFvs8A",
        "outputId": "93880275-afd9-4fe9-c3ab-7571d04f71a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: rasterio in c:\\users\\sandro\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.4.3)\n",
            "Requirement already satisfied: affine in c:\\users\\sandro\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rasterio) (2.4.0)\n",
            "Requirement already satisfied: attrs in c:\\users\\sandro\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rasterio) (24.2.0)\n",
            "Requirement already satisfied: certifi in c:\\users\\sandro\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rasterio) (2024.8.30)\n",
            "Requirement already satisfied: click>=4.0 in c:\\users\\sandro\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rasterio) (8.1.8)\n",
            "Requirement already satisfied: cligj>=0.5 in c:\\users\\sandro\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rasterio) (0.7.2)\n",
            "Requirement already satisfied: numpy>=1.24 in c:\\users\\sandro\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rasterio) (1.26.4)\n",
            "Requirement already satisfied: click-plugins in c:\\users\\sandro\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rasterio) (1.1.1)\n",
            "Requirement already satisfied: pyparsing in c:\\users\\sandro\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rasterio) (3.2.0)\n",
            "Requirement already satisfied: colorama in c:\\users\\sandro\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from click>=4.0->rasterio) (0.4.6)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: matplotlib in c:\\users\\sandro\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.9.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\sandro\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\sandro\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\sandro\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\sandro\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: numpy>=1.23 in c:\\users\\sandro\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\sandro\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\sandro\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\sandro\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\sandro\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\sandro\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install rasterio\n",
        "%pip install matplotlib\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import rasterio as rio\n",
        "from rasterio.plot import reshape_as_image\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kLOVPyVvs8D",
        "outputId": "6edb34f1-f142-4411-8dce-0782c343cd88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File 'EuroSATallBands.zip' already exists. Skipping download.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "zip_file_path = \"EuroSATallBands.zip\"\n",
        "\n",
        "if not os.path.exists(zip_file_path):\n",
        "    print(f\"File '{zip_file_path}' not found. Downloading...\")\n",
        "    #!powershell Invoke-WebRequest -Uri \"https://madm.dfki.de/files/sentinel/EuroSATallBands.zip\" -OutFile \"EuroSATallBands.zip\"\n",
        "\n",
        "    # Alternative download command for Linux & MacOS\n",
        "    !wget --no-check-certificate https://madm.dfki.de/files/sentinel/EuroSATallBands.zip\n",
        "\n",
        "else:\n",
        "    print(f\"File '{zip_file_path}' already exists. Skipping download.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOuSRo1Pvs8G"
      },
      "source": [
        "## EuroSat Data Loading\n",
        "\n",
        "First, let's collect all the files that we downloaded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHJi6UDtvs8G",
        "outputId": "3921ecb6-8e4a-4caa-cb11-b7ded9f51a56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Folder already exists at ./data\n"
          ]
        }
      ],
      "source": [
        "zip_file_path = \"EuroSATallBands.zip\"\n",
        "extraction_path = \"./data\"\n",
        "\n",
        "# Check if the extraction path exists\n",
        "if not os.path.exists(extraction_path):\n",
        "    shutil.unpack_archive(zip_file_path, extraction_path)\n",
        "    print(f\"Unpacked archive to {extraction_path}\")\n",
        "else:\n",
        "    print(f\"Folder already exists at {extraction_path}\")\n",
        "\n",
        "# change this to your eurosat path\n",
        "eurosat_dir = \"./data/ds/images/remote_sensing/otherDatasets/sentinel_2/tif\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8VJoLqlvs8H",
        "outputId": "8cd1847b-9192-4e06-e994-5db1a3a170aa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "27000"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "samples = glob.glob(os.path.join(eurosat_dir, \"*\", \"*.tif\"))\n",
        "len(samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCTDwCQlvs8H"
      },
      "source": [
        "We have 27,000 files across 10 classes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WcQhuFlvs8H"
      },
      "source": [
        "# Testset Data Loading\n",
        "\n",
        "The testset has a slightly different structure than Eurosat. There are no labels and the data is stored in `numpy` `.npy` instead of GTiff.\n",
        "\n",
        "First, we have to download the data from [Kaggle](https://www.kaggle.com/competitions/8-860-1-00-coding-challenge-2025/data)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ohulDvOvs8I",
        "outputId": "92b43520-25ff-44b4-f136-8a1a8d37b218"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File './testset.zip' already exists. Skipping download.\n",
            "Unpacked archive to ./data\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "4232"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "zip_test_file_path = \"./testset.zip\"\n",
        "extraction_path = \"./data\"\n",
        "\n",
        "testset_dir = os.path.join(extraction_path, \"testset\")\n",
        "\n",
        "if not os.path.exists(zip_test_file_path):\n",
        "    print(f\"File '{zip_test_file_path}' not found. Will download the testdata here\")\n",
        "    !wget https://github.com/sandrobl/ml-eurosat/raw/main/testset.zip\n",
        "\n",
        "    #Windows Powershell version\n",
        "    #!powershell Invoke-WebRequest -Uri \"https://github.com/sandrobl/ml-eurosat/raw/main/testset.zip\" -OutFile \"testset.zip\"\n",
        "\n",
        "else:\n",
        "    print(f\"File '{zip_test_file_path}' already exists. Skipping download.\")\n",
        "\n",
        "\n",
        "# Check if the testset directory exists\n",
        "if not os.path.exists(testset_dir):\n",
        "    shutil.unpack_archive(zip_test_file_path, extraction_path)\n",
        "    print(f\"Unpacked archive to {extraction_path}\")\n",
        "else:\n",
        "    print(f\"Testset folder already exists at {testset_dir}\")\n",
        "\n",
        "\n",
        "test_samples = glob.glob(os.path.join(testset_dir, \"*.npy\"))\n",
        "len(test_samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZtJBBDkvs8I"
      },
      "source": [
        "## Next steps\n",
        "\n",
        "Create a (deep learning) model to predict the most likely Eurosat class for each image of the testset. Think about creating the dataset class and data-loader for training, possible model architectures, and perhaps even how to best address the shift between train and test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_t_9sC_1vs8I",
        "outputId": "f41b1cb8-1a11-46b1-f0b8-d069645fae95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in c:\\users\\sandro\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.6.0+cu126)\n",
            "Requirement already satisfied: torchvision in c:\\users\\sandro\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.21.0+cu126)\n",
            "Requirement already satisfied: filelock in c:\\users\\sandro\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\sandro\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in c:\\users\\sandro\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\sandro\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in c:\\users\\sandro\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: setuptools in c:\\users\\sandro\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (75.4.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in c:\\users\\sandro\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\sandro\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\sandro\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\sandro\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sandro\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
            "c:\\Users\\Sandro\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "c:\\Users\\Sandro\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "True\n",
            "Epoch [1/5], Step [10/844], Loss: 1.5434\n",
            "Epoch [1/5], Step [20/844], Loss: 1.1680\n",
            "Epoch [1/5], Step [30/844], Loss: 1.3435\n",
            "Epoch [1/5], Step [40/844], Loss: 1.0486\n",
            "Epoch [1/5], Step [50/844], Loss: 1.0225\n",
            "Epoch [1/5], Step [60/844], Loss: 0.7460\n",
            "Epoch [1/5], Step [70/844], Loss: 0.7868\n",
            "Epoch [1/5], Step [80/844], Loss: 0.8435\n",
            "Epoch [1/5], Step [90/844], Loss: 0.7198\n",
            "Epoch [1/5], Step [100/844], Loss: 0.7753\n",
            "Epoch [1/5], Step [110/844], Loss: 0.8235\n",
            "Epoch [1/5], Step [120/844], Loss: 0.6877\n",
            "Epoch [1/5], Step [130/844], Loss: 0.5918\n",
            "Epoch [1/5], Step [140/844], Loss: 0.6357\n",
            "Epoch [1/5], Step [150/844], Loss: 0.5178\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Sandro\\AppData\\Local\\Temp\\ipykernel_15844\\1476928379.py:31: RuntimeWarning: invalid value encountered in divide\n",
            "  return (band_data - lower_perc) / (upper_perc - lower_perc)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Step [160/844], Loss: 0.6806\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[13], line 103\u001b[0m\n\u001b[0;32m    101\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m    102\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m--> 103\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Sandro\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:708\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    707\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 708\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    713\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    714\u001b[0m ):\n",
            "File \u001b[1;32mc:\\Users\\Sandro\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:764\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    763\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 764\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    765\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    766\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
            "File \u001b[1;32mc:\\Users\\Sandro\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
            "Cell \u001b[1;32mIn[13], line 51\u001b[0m, in \u001b[0;36mEurosatDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     47\u001b[0m label \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(sample_path))\n\u001b[0;32m     49\u001b[0m label_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses\u001b[38;5;241m.\u001b[39mindex(label)\n\u001b[1;32m---> 51\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mrio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m d:\n\u001b[0;32m     52\u001b[0m     img \u001b[38;5;241m=\u001b[39m d\u001b[38;5;241m.\u001b[39mread([\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m9\u001b[39m,\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m11\u001b[39m,\u001b[38;5;241m12\u001b[39m,\u001b[38;5;241m13\u001b[39m])\n\u001b[0;32m     53\u001b[0m     img \u001b[38;5;241m=\u001b[39m reshape_as_image(img)\n",
            "File \u001b[1;32mc:\\Users\\Sandro\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\rasterio\\env.py:463\u001b[0m, in \u001b[0;36mensure_env_with_credentials.<locals>.wrapper\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    460\u001b[0m     session \u001b[38;5;241m=\u001b[39m DummySession()\n\u001b[0;32m    462\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m env_ctor(session\u001b[38;5;241m=\u001b[39msession):\n\u001b[1;32m--> 463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Sandro\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\rasterio\\__init__.py:368\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, driver, width, height, count, crs, transform, dtype, nodata, sharing, opener, **kwargs)\u001b[0m\n\u001b[0;32m    365\u001b[0m     path \u001b[38;5;241m=\u001b[39m _parse_path(raw_dataset_path)\n\u001b[0;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 368\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mDatasetReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msharing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    370\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m get_writer_for_path(path, driver\u001b[38;5;241m=\u001b[39mdriver)(\n\u001b[0;32m    371\u001b[0m         path, mode, driver\u001b[38;5;241m=\u001b[39mdriver, sharing\u001b[38;5;241m=\u001b[39msharing, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    372\u001b[0m     )\n",
            "File \u001b[1;32mrasterio\\\\_base.pyx:314\u001b[0m, in \u001b[0;36mrasterio._base.DatasetBase.__init__\u001b[1;34m()\u001b[0m\n",
            "File \u001b[1;32mc:\\Users\\Sandro\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\rasterio\\_path.py:140\u001b[0m, in \u001b[0;36m_UnparsedPath.name\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Encapsulates legacy GDAL filenames\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \n\u001b[0;32m    133\u001b[0m \u001b[38;5;124;03mAttributes\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;124;03m    The legacy GDAL filename.\u001b[39;00m\n\u001b[0;32m    137\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    138\u001b[0m path \u001b[38;5;241m=\u001b[39m attr\u001b[38;5;241m.\u001b[39mib()\n\u001b[1;32m--> 140\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mname\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    142\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"The unparsed path's original path\"\"\"\u001b[39;00m\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "%pip install torch torchvision\n",
        "\n",
        "import os\n",
        "import rasterio\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models  # Import the missing module\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "classes = [\n",
        "    \"AnnualCrop\",\n",
        "    \"Forest\",\n",
        "    \"HerbaceousVegetation\",\n",
        "    \"Highway\",\n",
        "    \"Industrial\",\n",
        "    \"Pasture\",\n",
        "    \"PermanentCrop\",\n",
        "    \"Residential\",\n",
        "    \"River\",\n",
        "    \"SeaLake\",\n",
        "]\n",
        "\n",
        "def normalize_for_display(band_data):\n",
        "    band_data = np.array(band_data)\n",
        "    lower_perc = np.percentile(band_data, 2, axis=(0,1))\n",
        "    upper_perc = np.percentile(band_data, 98, axis=(0,1))\n",
        "    return (band_data - lower_perc) / (upper_perc - lower_perc)\n",
        "\n",
        "\n",
        "# Add the EurosatDataset class\n",
        "class EurosatDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, samples, transform=None):\n",
        "        self.samples = samples\n",
        "        self.transform = transform\n",
        "        self.classes = classes\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample_path = self.samples[idx]\n",
        "        #label = sample_path.split('/')[-1].split('_')[0]\n",
        "        label = os.path.basename(os.path.dirname(sample_path))\n",
        "\n",
        "        label_idx = self.classes.index(label)\n",
        "\n",
        "        with rio.open(sample_path, \"r\") as d:\n",
        "            img = d.read([1,2,3,4,5,6,7,8,9,10,11,12,13])\n",
        "            img = reshape_as_image(img)\n",
        "            img = normalize_for_display(img)\n",
        "            img = img[:, :, [3,2,1]]  # Extract RGB bands\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, label_idx\n",
        "\n",
        "# Define transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Create dataset instances\n",
        "train_dataset = EurosatDataset(samples, transform=transform)\n",
        "test_dataset = EurosatDataset(test_samples, transform=transform)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "class EurosatModel(nn.Module):  # Fix inheritance (nn.Module)\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(EurosatModel, self).__init__()  # Fix super() syntax\n",
        "        self.model = models.resnet50(pretrained=True)\n",
        "        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)\n",
        "\n",
        "    def forward(self, x):  # Fix indentation\n",
        "        return self.model(x)\n",
        "\n",
        "model = EurosatModel(num_classes=10)\n",
        "\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 15\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(torch.cuda.is_available())\n",
        "model.to(device)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 10 == 9:  # Print every 10 batches\n",
        "            print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {running_loss / 10:.4f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "torch.save(model.state_dict(), \"model_checkpoint.pth\")\n",
        "\n",
        "# ----------------------------------------------\n",
        "# 1. Define the EurostatDataset Class (REQUIRED)\n",
        "# ----------------------------------------------\n",
        "class EurostatDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.classes = sorted([cls for cls in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, cls))])\n",
        "        self.class_to_idx = {cls: i for i, cls in enumerate(self.classes)}\n",
        "        self.images = []\n",
        "\n",
        "        # Iterate through all subfolders (classes) in the root directory\n",
        "        for cls in self.classes:\n",
        "            cls_dir = os.path.join(root_dir, cls)  # Path to the class directory\n",
        "            # Iterate through all files in the class directory\n",
        "            for img_name in os.listdir(cls_dir):\n",
        "                if img_name.endswith('.tif'):  # Ensure images are .tif files\n",
        "                    # Append the image path and label to the images list\n",
        "                    self.images.append((os.path.join(cls_dir, img_name), self.class_to_idx[cls]))\n",
        "\n",
        "    def __len__(self):\n",
        "        # Return the total number of images in the dataset\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get the image path and label for the given index\n",
        "        img_path, label = self.images[idx]\n",
        "\n",
        "        # Open the image using rasterio and read it as a numpy array\n",
        "        with rasterio.open(img_path) as src:\n",
        "            image = src.read([4, 3, 2])  # Read RGB bands (R=4, G=3, B=2)\n",
        "            image = image.transpose(1, 2, 0)  # Change to HxWxC\n",
        "\n",
        "        # Convert numpy array to PIL Image\n",
        "        image = Image.fromarray(image.astype('uint8'), 'RGB')\n",
        "\n",
        "        # Apply any transformations to the image\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        # Return the transformed image and its label\n",
        "        return image, label\n",
        "# ----------------------------------------------\n",
        "# 2. Define Transforms and Load Test Data\n",
        "# ----------------------------------------------\n",
        "# Use the same transforms as during training\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),  # Resize images to 64x64\n",
        "    transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize images\n",
        "])\n",
        "\n",
        "# Load Test Dataset\n",
        "# Note: The root directory is corrected to point to the 'testset' folder\n",
        "test_dataset = EurostatDataset(\n",
        "    root_dir='./data/testset',\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# ----------------------------------------------\n",
        "# 3. Evaluation Loop\n",
        "# ----------------------------------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():  # Disable gradient calculation during evaluation\n",
        "    for inputs, labels in test_loader:\n",
        "        # Move inputs and labels to the appropriate device\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Get model predictions\n",
        "        outputs = model(inputs)\n",
        "        # Get the predicted class indices\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        # Update total and correct counts\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "# Calculate and print the test accuracy\n",
        "print(f'Test Accuracy: {100 * correct / total:.2f}%')\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
