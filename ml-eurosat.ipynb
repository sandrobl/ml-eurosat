{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FalwJeqyvs79"
      },
      "source": [
        "###  Coding Challenge - Getting Started\n",
        "\n",
        "<img align=\"right\" style=\"max-width: 200px; height: auto\" src=\"https://github.com/sandrobl/ml-eurosat/blob/main/hsg_logo.png?raw=1\">\n",
        "<img align=\"center\" style=\"max-width: 300px; height: auto\" src=\"https://github.com/sandrobl/ml-eurosat/blob/main/sentinel2.jpg?raw=1\">\n",
        "\n",
        "8,860,1.00 MCS Machine Learning, Spring Term 2025, University of St.Gallen (HSG)\n",
        "\n",
        "The lab environment of the **8,860,1.00 Machine Learning** course is powered by Jupyter Notebooks (https://jupyter.org), which allows one to perform a great deal of data analysis and statistical validation. In this first lab, we want to touch on the basic concepts and techniques of such notebooks. Furthermore, its capabilities will be demonstrated based on a few simple and introductory examples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdgXTGCEvs7-"
      },
      "source": [
        "### Objectives:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUQB7QtBvs7-"
      },
      "source": [
        "With the help of this notebook you should be able to:\n",
        "    \n",
        "> 1. Understand the basic funcitonality of the rasterio framework\n",
        "> 2. Apply rasterio to load GTiff data\n",
        "> 3. Visualize multi-band satellite imagery\n",
        "> 4. Perform basic band arithmetic to compute the normalized difference vegetation index (NDVI)\n",
        "> 5. Load and display samples from the challenge testset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AhbmTLQvs7_"
      },
      "source": [
        "## 2. Setup of the Jupyter Notebook Environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrBoV_N6vs7_"
      },
      "source": [
        "Similar to the previous labs, we need to import a couple of Python libraries that allow for data analysis and data visualization. We will use `os` and `glob` to collect the filepaths for the data samples, `numpy` for array operations, `matplotlib` to display images, and `rasterio` to handle raster data. You can find the documentation of the `rasterio` library with an overview of its functionality [here](https://rasterio.readthedocs.io)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1CEl9pSFvs8A",
        "outputId": "93880275-afd9-4fe9-c3ab-7571d04f71a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: rasterio in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.4.3)\n",
            "Requirement already satisfied: affine in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rasterio) (2.4.0)\n",
            "Requirement already satisfied: attrs in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rasterio) (25.3.0)\n",
            "Requirement already satisfied: certifi in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rasterio) (2025.1.31)\n",
            "Requirement already satisfied: click>=4.0 in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rasterio) (8.1.8)\n",
            "Requirement already satisfied: cligj>=0.5 in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rasterio) (0.7.2)\n",
            "Requirement already satisfied: numpy>=1.24 in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rasterio) (2.2.4)\n",
            "Requirement already satisfied: click-plugins in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rasterio) (1.1.1)\n",
            "Requirement already satisfied: pyparsing in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rasterio) (3.2.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\sandr\\appdata\\roaming\\python\\python313\\site-packages (from click>=4.0->rasterio) (0.4.6)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: matplotlib in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.10.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (2.2.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\sandr\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\sandr\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\sandr\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install rasterio\n",
        "%pip install matplotlib\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import rasterio as rio\n",
        "from rasterio.plot import reshape_as_image\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kLOVPyVvs8D",
        "outputId": "6edb34f1-f142-4411-8dce-0782c343cd88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File 'EuroSATallBands.zip' already exists. Skipping download.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "zip_file_path = \"EuroSATallBands.zip\"\n",
        "\n",
        "if not os.path.exists(zip_file_path):\n",
        "    print(f\"File '{zip_file_path}' not found. Downloading...\")\n",
        "    !powershell Invoke-WebRequest -Uri \"https://madm.dfki.de/files/sentinel/EuroSATallBands.zip\" -OutFile \"EuroSATallBands.zip\"\n",
        "\n",
        "    # Alternative download command for Linux & MacOS\n",
        "    #!wget --no-check-certificate https://madm.dfki.de/files/sentinel/EuroSATallBands.zip\n",
        "\n",
        "else:\n",
        "    print(f\"File '{zip_file_path}' already exists. Skipping download.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOuSRo1Pvs8G"
      },
      "source": [
        "## EuroSat Data Loading\n",
        "\n",
        "First, let's collect all the files that we downloaded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHJi6UDtvs8G",
        "outputId": "3921ecb6-8e4a-4caa-cb11-b7ded9f51a56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Folder already exists at ./data\n"
          ]
        }
      ],
      "source": [
        "zip_file_path = \"EuroSATallBands.zip\"\n",
        "extraction_path = \"./data\"\n",
        "\n",
        "# Check if the extraction path exists\n",
        "if not os.path.exists(extraction_path):\n",
        "    print(f\"Unpacked archive to {extraction_path}\")\n",
        "    shutil.unpack_archive(zip_file_path, extraction_path)\n",
        "else:\n",
        "    print(f\"Folder already exists at {extraction_path}\")\n",
        "\n",
        "# change this to your eurosat path\n",
        "eurosat_dir = \"./data/ds/images/remote_sensing/otherDatasets/sentinel_2/tif\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8VJoLqlvs8H",
        "outputId": "8cd1847b-9192-4e06-e994-5db1a3a170aa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "27000"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "samples = glob.glob(os.path.join(eurosat_dir, \"*\", \"*.tif\"))\n",
        "len(samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCTDwCQlvs8H"
      },
      "source": [
        "We have 27,000 files across 10 classes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WcQhuFlvs8H"
      },
      "source": [
        "# Testset Data Loading\n",
        "\n",
        "The testset has a slightly different structure than Eurosat. There are no labels and the data is stored in `numpy` `.npy` instead of GTiff.\n",
        "\n",
        "First, we have to download the data from [Kaggle](https://www.kaggle.com/competitions/8-860-1-00-coding-challenge-2025/data)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ohulDvOvs8I",
        "outputId": "92b43520-25ff-44b4-f136-8a1a8d37b218"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File './testset.zip' already exists. Skipping download.\n",
            "Testset folder already exists at ./data\\testset\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "4232"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "zip_test_file_path = \"./testset.zip\"\n",
        "extraction_path = \"./data\"\n",
        "\n",
        "testset_dir = os.path.join(extraction_path, \"testset\")\n",
        "\n",
        "if not os.path.exists(zip_test_file_path):\n",
        "    print(f\"File '{zip_test_file_path}' not found. Will download the testdata here\")\n",
        "    !wget https://github.com/sandrobl/ml-eurosat/raw/main/testset.zip\n",
        "\n",
        "    #Windows Powershell version\n",
        "    #!powershell Invoke-WebRequest -Uri \"https://github.com/sandrobl/ml-eurosat/raw/main/testset.zip\" -OutFile \"testset.zip\"\n",
        "\n",
        "else:\n",
        "    print(f\"File '{zip_test_file_path}' already exists. Skipping download.\")\n",
        "\n",
        "\n",
        "# Check if the testset directory exists\n",
        "if not os.path.exists(testset_dir):\n",
        "    print(f\"Unpacked archive to {extraction_path}\")\n",
        "    shutil.unpack_archive(zip_test_file_path, extraction_path)\n",
        "else:\n",
        "    print(f\"Testset folder already exists at {testset_dir}\")\n",
        "\n",
        "\n",
        "test_samples = glob.glob(os.path.join(testset_dir, \"*.npy\"))\n",
        "len(test_samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZtJBBDkvs8I"
      },
      "source": [
        "## Next steps\n",
        "\n",
        "Create a (deep learning) model to predict the most likely Eurosat class for each image of the testset. Think about creating the dataset class and data-loader for training, possible model architectures, and perhaps even how to best address the shift between train and test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_t_9sC_1vs8I",
        "outputId": "f41b1cb8-1a11-46b1-f0b8-d069645fae95"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
            "c:\\Users\\sandr\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "c:\\Users\\sandr\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.6.0+cu126)\n",
            "Requirement already satisfied: torchvision in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.21.0)\n",
            "Requirement already satisfied: torchsummary in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.5.1)\n",
            "Requirement already satisfied: pandas in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.2.3)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.6.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: setuptools in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (76.0.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torchvision) (2.2.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sandr\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (1.15.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\sandr\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Total samples in test_dataset: 4232\n",
            "Total number of batches: 67\n",
            "Total samples: 4232\n",
            "Using device: cuda\n",
            "Epoch [1/20], Step [10/422], Loss: 1.3677\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 172\u001b[39m\n\u001b[32m    170\u001b[39m model.train()\n\u001b[32m    171\u001b[39m running_loss = \u001b[32m0.0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sandr\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:708\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    711\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    712\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    714\u001b[39m ):\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sandr\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:764\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    762\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    763\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m764\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    765\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    766\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sandr\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 99\u001b[39m, in \u001b[36mEurostatDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m     97\u001b[39m \u001b[38;5;66;03m# Apply transformations\u001b[39;00m\n\u001b[32m     98\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transform:\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m     image = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m image, label\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sandr\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[39m, in \u001b[36mCompose.__call__\u001b[39m\u001b[34m(self, img)\u001b[39m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transforms:\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m         img = \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sandr\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:137\u001b[39m, in \u001b[36mToTensor.__call__\u001b[39m\u001b[34m(self, pic)\u001b[39m\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[32m    130\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    131\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[33;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    135\u001b[39m \u001b[33;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[32m    136\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sandr\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torchvision\\transforms\\functional.py:176\u001b[39m, in \u001b[36mto_tensor\u001b[39m\u001b[34m(pic)\u001b[39m\n\u001b[32m    174\u001b[39m img = img.permute((\u001b[32m2\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m)).contiguous()\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(img, torch.ByteTensor):\n\u001b[32m--> \u001b[39m\u001b[32m176\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdefault_float_dtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdiv\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m255\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# Install necessary libraries\n",
        "%pip install torch torchvision torchsummary pandas scikit-learn\n",
        "\n",
        "\n",
        "import rasterio  # Required for .tif images\n",
        "import datetime\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import rasterio as rio\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    # ------------------------\n",
        "    # 1. Define Dataset Class\n",
        "    # ------------------------\n",
        "    classes = [\n",
        "        \"AnnualCrop\", \"Forest\", \"HerbaceousVegetation\", \"Highway\",\n",
        "        \"Industrial\", \"Pasture\", \"PermanentCrop\", \"Residential\",\n",
        "        \"River\", \"SeaLake\",\n",
        "    ]\n",
        "\n",
        "    BASE_DIR = os.getcwd() \n",
        "\n",
        "\n",
        "    def normalize_for_display(band_data):\n",
        "        band_data = np.array(band_data, dtype=np.float32) / 65535.0  # Normalize to 0-1\n",
        "        mean = np.mean(band_data, axis=(0, 1))\n",
        "        std = np.std(band_data, axis=(0, 1))\n",
        "        return (band_data - mean) / (std + 1e-7)\n",
        "\n",
        "\n",
        "    class EurostatDataset(Dataset):\n",
        "        def __init__(self, root_dir, labels_csv=None, transform=None, file_type=\"tif\"):\n",
        "            self.root_dir = root_dir\n",
        "            self.transform = transform\n",
        "            self.file_type = file_type  # \"tif\" for training, \"npy\" for testing\n",
        "            self.images = []\n",
        "            self.labels = []\n",
        "            self.class_to_idx = {}  # Class label mapping\n",
        "\n",
        "            if labels_csv:\n",
        "                # **For TEST SET (Uses CSV for labels)**\n",
        "                self.labels_df = pd.read_csv(labels_csv)\n",
        "                self.class_to_idx = {cls: idx for idx, cls in enumerate(sorted(self.labels_df['label'].unique()))}\n",
        "\n",
        "                for _, row in self.labels_df.iterrows():\n",
        "                    file_name = f\"test_{row['test_id']}.npy\"\n",
        "                    file_path = os.path.join(root_dir, file_name)\n",
        "                    if os.path.exists(file_path):\n",
        "                        self.images.append(file_path)\n",
        "                        self.labels.append(self.class_to_idx[row['label']])\n",
        "            else:\n",
        "                # **For TRAIN SET (Auto-labels based on folder names)**\n",
        "                folders = sorted(os.listdir(root_dir))\n",
        "                self.class_to_idx = {folder: idx for idx, folder in enumerate(folders)}\n",
        "\n",
        "                for folder in folders:\n",
        "                    folder_path = os.path.join(root_dir, folder)\n",
        "                    if os.path.isdir(folder_path):\n",
        "                        for file in os.listdir(folder_path):\n",
        "                            if file.endswith(f\".{file_type}\"):  # Match file type\n",
        "                                self.images.append(os.path.join(folder_path, file))\n",
        "                                self.labels.append(self.class_to_idx[folder])\n",
        "\n",
        "        def __len__(self):\n",
        "            return len(self.images)\n",
        "\n",
        "        def __getitem__(self, idx):\n",
        "            img_path = self.images[idx]  \n",
        "            label = self.labels[idx]\n",
        "\n",
        "            if self.file_type == \"tif\":\n",
        "                # **Load .tif for training**\n",
        "                with rasterio.open(img_path) as src:\n",
        "                    image = src.read([1, 2, 3])  # Extract RGB bands\n",
        "                    image = np.moveaxis(image, 0, -1)  # Convert from (C, H, W) â†’ (H, W, C)\n",
        "            else:\n",
        "                # **Load .npy for testing**\n",
        "                image = np.load(img_path)[:, :, :3]  # Extract first 3 bands (RGB)\n",
        "\n",
        "            # Normalize: Convert to float32 and scale to [0, 255]\n",
        "            image = (image / image.max()) * 255.0  \n",
        "            image = image.astype(np.uint8)\n",
        "\n",
        "            # Convert to PIL image\n",
        "            image = Image.fromarray(image)\n",
        "\n",
        "            # Apply transformations\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "\n",
        "            return image, label\n",
        "\n",
        "\n",
        "    # ------------------------\n",
        "    # 2. Define Transformations\n",
        "    # ------------------------\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((64, 64)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    # ------------------------\n",
        "    # 3. Load Dataset & DataLoader\n",
        "    # ------------------------\n",
        "    test_dataset = EurostatDataset(\n",
        "        \n",
        "        root_dir=os.path.join(BASE_DIR, \"data\", \"testset\"),\n",
        "        labels_csv=os.path.join(BASE_DIR, \"test_labels.csv\"),\n",
        "        transform=transform,\n",
        "        file_type=\"npy\"\n",
        "    )\n",
        "\n",
        "    print(f\"Total samples in test_dataset: {len(test_dataset)}\")\n",
        "\n",
        "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "    print(f\"Total number of batches: {len(test_loader)}\")\n",
        "    print(f\"Total samples: {len(test_loader.dataset)}\")\n",
        "\n",
        "    # ------------------------\n",
        "    # 4. Define Model\n",
        "    # ------------------------\n",
        "    class EurosatModel(nn.Module):\n",
        "        def __init__(self, num_classes=10):\n",
        "            super(EurosatModel, self).__init__()\n",
        "            self.model = models.resnet50(pretrained=True)\n",
        "            self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)\n",
        "\n",
        "        def forward(self, x):\n",
        "            return self.model(x)\n",
        "\n",
        "    model = EurosatModel(num_classes=10)\n",
        "\n",
        "    # ------------------------\n",
        "    # 5. Training Setup\n",
        "    # ------------------------\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
        "\n",
        "    # ------------------------\n",
        "    # 6. Training Loop\n",
        "    # ------------------------\n",
        "\n",
        "    train_dataset = EurostatDataset(\n",
        "        root_dir=os.path.join(BASE_DIR, \"data\", \"ds\", \"images\", \"remote_sensing\", \"otherDatasets\", \"sentinel_2\", \"tif\"),\n",
        "        transform=transform,\n",
        "        file_type=\"tif\"\n",
        "    )\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=0, pin_memory=True)\n",
        "\n",
        "    num_epochs = 20\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for i, (inputs, labels) in enumerate(train_loader):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            if i % 10 == 9:\n",
        "                print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {running_loss / 10:.4f}')\n",
        "                running_loss = 0.0\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "    print('Finished Training')\n",
        "\n",
        "    # ------------------------\n",
        "    # 7. Evaluation Loop (Fixed)\n",
        "    # ------------------------\n",
        "    model.to(device)\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    predictions = []  # Store predictions\n",
        "\n",
        "    with torch.no_grad():  \n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "    print(f\"First 10 test predictions: {predictions[:10]}\")\n",
        "    print(f'Test Accuracy: {100 * correct / total:.2f}%')\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "\n",
        "    print(f\"First 10 test predictions: {predictions[:10]}\")\n",
        "    print(f'Test Accuracy: {100 * correct / total:.2f}%')\n",
        "\n",
        "    # Save model\n",
        "    current_time = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    # Create a filename with the current date, time, and accuracy\n",
        "    filename = f\"model_checkpoint_accuracy_{accuracy:.2f}_{current_time}.pth\"\n",
        "\n",
        "    torch.save(model.state_dict(), os.path.join(\"./trained_models\", filename))\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
