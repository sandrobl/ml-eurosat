{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FalwJeqyvs79"
      },
      "source": [
        "###  Coding Challenge - Getting Started\n",
        "\n",
        "<img align=\"right\" style=\"max-width: 200px; height: auto\" src=\"https://github.com/sandrobl/ml-eurosat/blob/main/hsg_logo.png?raw=1\">\n",
        "<img align=\"center\" style=\"max-width: 300px; height: auto\" src=\"https://github.com/sandrobl/ml-eurosat/blob/main/sentinel2.jpg?raw=1\">\n",
        "\n",
        "8,860,1.00 MCS Machine Learning, Spring Term 2025, University of St.Gallen (HSG)\n",
        "\n",
        "The lab environment of the **8,860,1.00 Machine Learning** course is powered by Jupyter Notebooks (https://jupyter.org), which allows one to perform a great deal of data analysis and statistical validation. In this first lab, we want to touch on the basic concepts and techniques of such notebooks. Furthermore, its capabilities will be demonstrated based on a few simple and introductory examples."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdgXTGCEvs7-"
      },
      "source": [
        "### Objectives:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUQB7QtBvs7-"
      },
      "source": [
        "With the help of this notebook you should be able to:\n",
        "    \n",
        "> 1. Understand the basic funcitonality of the rasterio framework\n",
        "> 2. Apply rasterio to load GTiff data\n",
        "> 3. Visualize multi-band satellite imagery\n",
        "> 4. Perform basic band arithmetic to compute the normalized difference vegetation index (NDVI)\n",
        "> 5. Load and display samples from the challenge testset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-AhbmTLQvs7_"
      },
      "source": [
        "## 2. Setup of the Jupyter Notebook Environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrBoV_N6vs7_"
      },
      "source": [
        "Similar to the previous labs, we need to import a couple of Python libraries that allow for data analysis and data visualization. We will use `os` and `glob` to collect the filepaths for the data samples, `numpy` for array operations, `matplotlib` to display images, and `rasterio` to handle raster data. You can find the documentation of the `rasterio` library with an overview of its functionality [here](https://rasterio.readthedocs.io)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1CEl9pSFvs8A",
        "outputId": "02f7817b-138d-44d8-a4e9-a8b0cba05665"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: rasterio in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.4.3)\n",
            "Requirement already satisfied: affine in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rasterio) (2.4.0)\n",
            "Requirement already satisfied: attrs in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rasterio) (25.3.0)\n",
            "Requirement already satisfied: certifi in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rasterio) (2025.1.31)\n",
            "Requirement already satisfied: click>=4.0 in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rasterio) (8.1.8)\n",
            "Requirement already satisfied: cligj>=0.5 in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rasterio) (0.7.2)\n",
            "Requirement already satisfied: numpy>=1.24 in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rasterio) (2.2.4)\n",
            "Requirement already satisfied: click-plugins in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rasterio) (1.1.1)\n",
            "Requirement already satisfied: pyparsing in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rasterio) (3.2.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\sandr\\appdata\\roaming\\python\\python313\\site-packages (from click>=4.0->rasterio) (0.4.6)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
            "\n",
            "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: matplotlib in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.10.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (2.2.4)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\sandr\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\sandr\\appdata\\roaming\\python\\python313\\site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\sandr\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install rasterio\n",
        "%pip install matplotlib\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import rasterio as rio\n",
        "from rasterio.plot import reshape_as_image\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5s-S27V5vs8C"
      },
      "source": [
        "### Dataset Download\n",
        "<img align=\"center\" style=\"max-width: 300px; height: auto\" src=\"https://github.com/sandrobl/ml-eurosat/blob/main/eurosat.png?raw=1\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhIuwKcTvs8D"
      },
      "source": [
        "The Eurosat dataset is available on [github](https://github.com/phelber/EuroSAT). You can download and unpack the data from there. Note that this repository includes RGB and multi-spectral versions of Eurosat. Note that the testdata is multi-spectral.\n",
        "\n",
        "The multi-spectral (MS) version can be downloaded with the following command:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-kLOVPyVvs8D",
        "outputId": "69ba0c59-2c5a-4b0b-c8a9-91ec0802f8cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File 'EuroSATallBands.zip' already exists. Skipping download.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "zip_file_path = \"EuroSATallBands.zip\"\n",
        "\n",
        "if not os.path.exists(zip_file_path):\n",
        "    print(f\"File '{zip_file_path}' not found. Downloading...\")\n",
        "    !powershell Invoke-WebRequest -Uri \"https://madm.dfki.de/files/sentinel/EuroSATallBands.zip\" -OutFile \"EuroSATallBands.zip\"\n",
        "\n",
        "    # Alternative download command for Linux & MacOS\n",
        "    #!wget --no-check-certificate https://madm.dfki.de/files/sentinel/EuroSATallBands.zip\n",
        "\n",
        "else:\n",
        "    print(f\"File '{zip_file_path}' already exists. Skipping download.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKTxVtuOvs8E"
      },
      "source": [
        "### Data visualization\n",
        "Let's define a function to visualize the Eurosat data with `matplotlib`. In the 13-band multispectral images of Sentinel-2, the 13 values of each pixel correspond to the reflectance values at different wavelengths. These numbers are not normalized for visualization with `matplotlib`, which expects inputs to be `int` in the `[0-255]` or `float` in the `[0.-1.]` range."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cz7lHpdFvs8F"
      },
      "outputs": [],
      "source": [
        "def normalize_for_display(band_data):\n",
        "    \"\"\"Normalize multi-spectral imagery across bands.\n",
        "    The input is expected to be in HxWxC format, e.g. 64x64x13.\n",
        "    To account for outliers (e.g. extremly high values due to\n",
        "    reflective surfaces), we normalize with the 2- and 98-percentiles\n",
        "    instead of minimum and maximum of each band.\n",
        "    \"\"\"\n",
        "    band_data = np.array(band_data)\n",
        "    lower_perc = np.percentile(band_data, 2, axis=(0,1))\n",
        "    upper_perc = np.percentile(band_data, 98, axis=(0,1))\n",
        "\n",
        "    return (band_data - lower_perc) / (upper_perc - lower_perc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOuSRo1Pvs8G"
      },
      "source": [
        "## EuroSat Data Loading\n",
        "\n",
        "First, let's collect all the files that we downloaded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHJi6UDtvs8G",
        "outputId": "acfbd34a-cc88-4f49-95be-d0b0597b1b22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Folder already exists at ./data\n"
          ]
        }
      ],
      "source": [
        "zip_file_path = \"EuroSATallBands.zip\"\n",
        "extraction_path = \"./data\"\n",
        "\n",
        "# Check if the extraction path exists\n",
        "if not os.path.exists(extraction_path):\n",
        "    shutil.unpack_archive(zip_file_path, extraction_path)\n",
        "    print(f\"Unpacked archive to {extraction_path}\")\n",
        "else:\n",
        "    print(f\"Folder already exists at {extraction_path}\")\n",
        "\n",
        "# change this to your eurosat path\n",
        "eurosat_dir = \"./data/ds/images/remote_sensing/otherDatasets/sentinel_2/tif\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8VJoLqlvs8H",
        "outputId": "ab893322-0980-4dc8-9b48-f094a61cca8d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "27000"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "samples = glob.glob(os.path.join(eurosat_dir, \"*\", \"*.tif\"))\n",
        "len(samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCTDwCQlvs8H"
      },
      "source": [
        "We have 27,000 files across 10 classes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxpopWE7vs8H"
      },
      "source": [
        "We can use `rasterio.open` to open the `GTiff` file. We can then `read` from the file. By default `read()` without arguments will load all bands. Individual bands can be specified as a list with one-based indices. Therefore, the RGB bands can be read with `read([4,3,2])`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WcQhuFlvs8H"
      },
      "source": [
        "# Testset Data Loading\n",
        "\n",
        "The testset has a slightly different structure than Eurosat. There are no labels and the data is stored in `numpy` `.npy` instead of GTiff.\n",
        "\n",
        "First, we have to download the data from [Kaggle](https://www.kaggle.com/competitions/8-860-1-00-coding-challenge-2025/data)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ohulDvOvs8I",
        "outputId": "9d261bb0-f7cb-4621-dcba-6288ba81b3a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File 'EuroSATallBands.zip' already exists. Skipping download.\n",
            "Testset folder already exists at ./data\\testset\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "4232"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "zip_test_file_path = \"./testset.zip\"\n",
        "extraction_path = \"./data\"\n",
        "\n",
        "testset_dir = os.path.join(extraction_path, \"testset\")\n",
        "\n",
        "if not os.path.exists(zip_file_path):\n",
        "    print(f\"File '{zip_file_path}' not found. Download the testset from here https://www.kaggle.com/competitions/8-860-1-00-coding-challenge-2025/data?select=testset, and create a zip file of the folder testet\")\n",
        "\n",
        "else:\n",
        "    print(f\"File '{zip_file_path}' already exists. Skipping download.\")\n",
        "\n",
        "\n",
        "# Check if the testset directory exists\n",
        "if not os.path.exists(testset_dir):\n",
        "    shutil.unpack_archive(zip_test_file_path, extraction_path)\n",
        "    print(f\"Unpacked archive to {extraction_path}\")\n",
        "else:\n",
        "    print(f\"Testset folder already exists at {testset_dir}\")\n",
        "\n",
        "\n",
        "test_samples = glob.glob(os.path.join(testset_dir, \"*.npy\"))\n",
        "len(test_samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZtJBBDkvs8I"
      },
      "source": [
        "## Next steps\n",
        "\n",
        "Create a (deep learning) model to predict the most likely Eurosat class for each image of the testset. Think about creating the dataset class and data-loader for training, possible model architectures, and perhaps even how to best address the shift between train and test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_t_9sC_1vs8I",
        "outputId": "a5a38e03-26e1-4b84-f74f-49106323418e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
            "c:\\Users\\sandr\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "c:\\Users\\sandr\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.6.0+cu126)\n",
            "Requirement already satisfied: torchvision in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.21.0)\n",
            "Requirement already satisfied: filelock in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: setuptools in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (76.0.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torchvision) (2.2.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sandr\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "True\n",
            "Epoch [1/5], Step [10/844], Loss: 1.5238\n",
            "Epoch [1/5], Step [20/844], Loss: 1.5319\n",
            "Epoch [1/5], Step [30/844], Loss: 1.1404\n",
            "Epoch [1/5], Step [40/844], Loss: 0.8367\n",
            "Epoch [1/5], Step [50/844], Loss: 0.9360\n",
            "Epoch [1/5], Step [60/844], Loss: 0.6664\n",
            "Epoch [1/5], Step [70/844], Loss: 0.9099\n",
            "Epoch [1/5], Step [80/844], Loss: 0.8731\n",
            "Epoch [1/5], Step [90/844], Loss: 0.8594\n",
            "Epoch [1/5], Step [100/844], Loss: 0.7922\n",
            "Epoch [1/5], Step [110/844], Loss: 0.7933\n",
            "Epoch [1/5], Step [120/844], Loss: 0.7812\n",
            "Epoch [1/5], Step [130/844], Loss: 0.6103\n",
            "Epoch [1/5], Step [140/844], Loss: 0.7396\n",
            "Epoch [1/5], Step [150/844], Loss: 0.6373\n",
            "Epoch [1/5], Step [160/844], Loss: 0.7257\n",
            "Epoch [1/5], Step [170/844], Loss: 0.5239\n",
            "Epoch [1/5], Step [180/844], Loss: 0.6360\n",
            "Epoch [1/5], Step [190/844], Loss: 0.7002\n",
            "Epoch [1/5], Step [200/844], Loss: 0.6531\n",
            "Epoch [1/5], Step [210/844], Loss: 0.5440\n",
            "Epoch [1/5], Step [220/844], Loss: 0.6477\n",
            "Epoch [1/5], Step [230/844], Loss: 0.6225\n",
            "Epoch [1/5], Step [240/844], Loss: 0.7150\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\sandr\\AppData\\Local\\Temp\\ipykernel_19224\\803103569.py:12: RuntimeWarning: invalid value encountered in divide\n",
            "  return (band_data - lower_perc) / (upper_perc - lower_perc)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/5], Step [250/844], Loss: 0.5104\n",
            "Epoch [1/5], Step [260/844], Loss: 0.4051\n",
            "Epoch [1/5], Step [270/844], Loss: 0.5416\n",
            "Epoch [1/5], Step [280/844], Loss: 0.6113\n",
            "Epoch [1/5], Step [290/844], Loss: 0.4686\n",
            "Epoch [1/5], Step [300/844], Loss: 0.6109\n",
            "Epoch [1/5], Step [310/844], Loss: 0.7503\n",
            "Epoch [1/5], Step [320/844], Loss: 0.4905\n",
            "Epoch [1/5], Step [330/844], Loss: 0.5993\n",
            "Epoch [1/5], Step [340/844], Loss: 0.5408\n",
            "Epoch [1/5], Step [350/844], Loss: 0.5111\n",
            "Epoch [1/5], Step [360/844], Loss: 0.4509\n",
            "Epoch [1/5], Step [370/844], Loss: 0.4872\n",
            "Epoch [1/5], Step [380/844], Loss: 0.5667\n",
            "Epoch [1/5], Step [390/844], Loss: 0.5057\n",
            "Epoch [1/5], Step [400/844], Loss: 0.4743\n",
            "Epoch [1/5], Step [410/844], Loss: 0.4719\n",
            "Epoch [1/5], Step [420/844], Loss: 0.5054\n",
            "Epoch [1/5], Step [430/844], Loss: 0.4414\n",
            "Epoch [1/5], Step [440/844], Loss: 0.5499\n",
            "Epoch [1/5], Step [450/844], Loss: 0.5999\n",
            "Epoch [1/5], Step [460/844], Loss: 0.5394\n",
            "Epoch [1/5], Step [470/844], Loss: 0.5385\n",
            "Epoch [1/5], Step [480/844], Loss: 0.4898\n",
            "Epoch [1/5], Step [490/844], Loss: 0.4264\n",
            "Epoch [1/5], Step [500/844], Loss: 0.4758\n",
            "Epoch [1/5], Step [510/844], Loss: 0.4766\n",
            "Epoch [1/5], Step [520/844], Loss: 0.4638\n",
            "Epoch [1/5], Step [530/844], Loss: 0.5447\n",
            "Epoch [1/5], Step [540/844], Loss: 0.3552\n",
            "Epoch [1/5], Step [550/844], Loss: 0.5475\n",
            "Epoch [1/5], Step [560/844], Loss: 0.5196\n",
            "Epoch [1/5], Step [570/844], Loss: 0.5351\n",
            "Epoch [1/5], Step [580/844], Loss: 0.5414\n",
            "Epoch [1/5], Step [590/844], Loss: 0.5129\n",
            "Epoch [1/5], Step [600/844], Loss: 0.4852\n",
            "Epoch [1/5], Step [610/844], Loss: 0.4690\n",
            "Epoch [1/5], Step [620/844], Loss: 0.4164\n",
            "Epoch [1/5], Step [630/844], Loss: 0.3196\n",
            "Epoch [1/5], Step [640/844], Loss: 0.4071\n",
            "Epoch [1/5], Step [650/844], Loss: 0.4739\n",
            "Epoch [1/5], Step [660/844], Loss: 0.4540\n",
            "Epoch [1/5], Step [670/844], Loss: 0.4696\n",
            "Epoch [1/5], Step [680/844], Loss: 0.4868\n",
            "Epoch [1/5], Step [690/844], Loss: 0.5328\n",
            "Epoch [1/5], Step [700/844], Loss: 0.6024\n",
            "Epoch [1/5], Step [710/844], Loss: 0.5950\n",
            "Epoch [1/5], Step [720/844], Loss: 0.4444\n",
            "Epoch [1/5], Step [730/844], Loss: 0.5290\n",
            "Epoch [1/5], Step [740/844], Loss: 0.5069\n",
            "Epoch [1/5], Step [750/844], Loss: 0.5038\n",
            "Epoch [1/5], Step [760/844], Loss: 0.5790\n",
            "Epoch [1/5], Step [770/844], Loss: 0.5040\n",
            "Epoch [1/5], Step [780/844], Loss: 0.3639\n",
            "Epoch [1/5], Step [790/844], Loss: 0.4280\n",
            "Epoch [1/5], Step [800/844], Loss: 0.4106\n",
            "Epoch [1/5], Step [810/844], Loss: 0.5261\n",
            "Epoch [1/5], Step [820/844], Loss: 0.4114\n",
            "Epoch [1/5], Step [830/844], Loss: 0.4565\n",
            "Epoch [1/5], Step [840/844], Loss: 0.4117\n",
            "Epoch [2/5], Step [10/844], Loss: 0.3032\n",
            "Epoch [2/5], Step [20/844], Loss: 0.2880\n",
            "Epoch [2/5], Step [30/844], Loss: 0.2857\n",
            "Epoch [2/5], Step [40/844], Loss: 0.2815\n",
            "Epoch [2/5], Step [50/844], Loss: 0.2853\n",
            "Epoch [2/5], Step [60/844], Loss: 0.5044\n",
            "Epoch [2/5], Step [70/844], Loss: 0.4280\n",
            "Epoch [2/5], Step [80/844], Loss: 0.4238\n",
            "Epoch [2/5], Step [90/844], Loss: 0.3788\n",
            "Epoch [2/5], Step [100/844], Loss: 0.3827\n",
            "Epoch [2/5], Step [110/844], Loss: 0.4212\n",
            "Epoch [2/5], Step [120/844], Loss: 0.4519\n",
            "Epoch [2/5], Step [130/844], Loss: 0.3392\n",
            "Epoch [2/5], Step [140/844], Loss: 0.3302\n",
            "Epoch [2/5], Step [150/844], Loss: 0.3706\n",
            "Epoch [2/5], Step [160/844], Loss: 0.4192\n",
            "Epoch [2/5], Step [170/844], Loss: 0.3437\n",
            "Epoch [2/5], Step [180/844], Loss: 0.3908\n",
            "Epoch [2/5], Step [190/844], Loss: 0.4109\n",
            "Epoch [2/5], Step [200/844], Loss: 0.3768\n",
            "Epoch [2/5], Step [210/844], Loss: 0.3384\n",
            "Epoch [2/5], Step [220/844], Loss: 0.2774\n",
            "Epoch [2/5], Step [230/844], Loss: 0.2276\n",
            "Epoch [2/5], Step [240/844], Loss: 0.3383\n",
            "Epoch [2/5], Step [250/844], Loss: 0.3142\n",
            "Epoch [2/5], Step [260/844], Loss: 0.3611\n",
            "Epoch [2/5], Step [270/844], Loss: 0.3469\n",
            "Epoch [2/5], Step [280/844], Loss: 0.4786\n",
            "Epoch [2/5], Step [290/844], Loss: 0.3558\n",
            "Epoch [2/5], Step [300/844], Loss: 0.5050\n",
            "Epoch [2/5], Step [310/844], Loss: 0.3628\n",
            "Epoch [2/5], Step [320/844], Loss: 0.4471\n",
            "Epoch [2/5], Step [330/844], Loss: 0.4883\n",
            "Epoch [2/5], Step [340/844], Loss: 0.4103\n",
            "Epoch [2/5], Step [350/844], Loss: 0.3518\n",
            "Epoch [2/5], Step [360/844], Loss: 0.3411\n",
            "Epoch [2/5], Step [370/844], Loss: 0.3053\n",
            "Epoch [2/5], Step [380/844], Loss: 0.2696\n",
            "Epoch [2/5], Step [390/844], Loss: 0.3200\n",
            "Epoch [2/5], Step [400/844], Loss: 0.3680\n",
            "Epoch [2/5], Step [410/844], Loss: 0.2880\n",
            "Epoch [2/5], Step [420/844], Loss: 0.3628\n",
            "Epoch [2/5], Step [430/844], Loss: 0.4521\n",
            "Epoch [2/5], Step [440/844], Loss: 0.4917\n",
            "Epoch [2/5], Step [450/844], Loss: 0.3825\n",
            "Epoch [2/5], Step [460/844], Loss: 0.3921\n",
            "Epoch [2/5], Step [470/844], Loss: 0.4026\n",
            "Epoch [2/5], Step [480/844], Loss: 0.2696\n",
            "Epoch [2/5], Step [490/844], Loss: 0.2735\n",
            "Epoch [2/5], Step [500/844], Loss: 0.3518\n",
            "Epoch [2/5], Step [510/844], Loss: 0.2621\n",
            "Epoch [2/5], Step [520/844], Loss: 0.4438\n",
            "Epoch [2/5], Step [530/844], Loss: 0.3758\n",
            "Epoch [2/5], Step [540/844], Loss: 0.3469\n",
            "Epoch [2/5], Step [550/844], Loss: 0.3091\n",
            "Epoch [2/5], Step [560/844], Loss: 0.3643\n",
            "Epoch [2/5], Step [570/844], Loss: 0.3434\n",
            "Epoch [2/5], Step [580/844], Loss: 0.3502\n",
            "Epoch [2/5], Step [590/844], Loss: 0.3581\n",
            "Epoch [2/5], Step [600/844], Loss: 0.3271\n",
            "Epoch [2/5], Step [610/844], Loss: 0.3555\n"
          ]
        }
      ],
      "source": [
        "%pip install torch torchvision\n",
        "\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models  # Import the missing module\n",
        "import torch.optim as optim\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "import rasterio\n",
        "\n",
        "classes = [\n",
        "    \"AnnualCrop\",\n",
        "    \"Forest\",\n",
        "    \"HerbaceousVegetation\",\n",
        "    \"Highway\",\n",
        "    \"Industrial\",\n",
        "    \"Pasture\",\n",
        "    \"PermanentCrop\",\n",
        "    \"Residential\",\n",
        "    \"River\",\n",
        "    \"SeaLake\",\n",
        "]\n",
        "\n",
        "# Add the EurosatDataset class\n",
        "class EurosatDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, samples, transform=None):\n",
        "        self.samples = samples\n",
        "        self.transform = transform\n",
        "        self.classes = classes\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample_path = self.samples[idx]\n",
        "        #label = sample_path.split('/')[-1].split('_')[0]\n",
        "        label = os.path.basename(os.path.dirname(sample_path))\n",
        "\n",
        "        label_idx = self.classes.index(label)\n",
        "\n",
        "        with rio.open(sample_path, \"r\") as d:\n",
        "            img = d.read([1,2,3,4,5,6,7,8,9,10,11,12,13])\n",
        "            img = reshape_as_image(img)\n",
        "            img = normalize_for_display(img)\n",
        "            img = img[:, :, [3,2,1]]  # Extract RGB bands\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, label_idx\n",
        "\n",
        "# Define transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToPILImage(),\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Create dataset instances\n",
        "train_dataset = EurosatDataset(samples, transform=transform)\n",
        "test_dataset = EurosatDataset(test_samples, transform=transform)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "class EurosatModel(nn.Module):  # Fix inheritance (nn.Module)\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(EurosatModel, self).__init__()  # Fix super() syntax\n",
        "        self.model = models.resnet18(pretrained=True)\n",
        "        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)\n",
        "\n",
        "    def forward(self, x):  # Fix indentation\n",
        "        return self.model(x)\n",
        "\n",
        "model = EurosatModel(num_classes=10)\n",
        "\n",
        "\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 5\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(torch.cuda.is_available())\n",
        "model.to(device)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(train_loader):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 10 == 9:  # Print every 10 batches\n",
        "            print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {running_loss / 10:.4f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "torch.save(model.state_dict(), \"model_checkpoint.pth\")\n",
        "\n",
        "# ----------------------------------------------\n",
        "# 1. Define the EurostatDataset Class (REQUIRED)\n",
        "# ----------------------------------------------\n",
        "class EurostatDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.classes = sorted([cls for cls in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, cls))])\n",
        "        self.class_to_idx = {cls: i for i, cls in enumerate(self.classes)}\n",
        "        self.images = []\n",
        "\n",
        "        # Iterate through all subfolders (classes) in the root directory\n",
        "        for cls in self.classes:\n",
        "            cls_dir = os.path.join(root_dir, cls)  # Path to the class directory\n",
        "            # Iterate through all files in the class directory\n",
        "            for img_name in os.listdir(cls_dir):\n",
        "                if img_name.endswith('.tif'):  # Ensure images are .tif files\n",
        "                    # Append the image path and label to the images list\n",
        "                    self.images.append((os.path.join(cls_dir, img_name), self.class_to_idx[cls]))\n",
        "\n",
        "    def __len__(self):\n",
        "        # Return the total number of images in the dataset\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get the image path and label for the given index\n",
        "        img_path, label = self.images[idx]\n",
        "\n",
        "        # Open the image using rasterio and read it as a numpy array\n",
        "        with rasterio.open(img_path) as src:\n",
        "            image = src.read([4, 3, 2])  # Read RGB bands (R=4, G=3, B=2)\n",
        "            image = image.transpose(1, 2, 0)  # Change to HxWxC\n",
        "\n",
        "        # Convert numpy array to PIL Image\n",
        "        image = Image.fromarray(image.astype('uint8'), 'RGB')\n",
        "\n",
        "        # Apply any transformations to the image\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        # Return the transformed image and its label\n",
        "        return image, label\n",
        "# ----------------------------------------------\n",
        "# 2. Define Transforms and Load Test Data\n",
        "# ----------------------------------------------\n",
        "# Use the same transforms as during training\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),  # Resize images to 64x64\n",
        "    transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize images\n",
        "])\n",
        "\n",
        "# Load Test Dataset\n",
        "# Note: The root directory is corrected to point to the 'testset' folder\n",
        "test_dataset = EurostatDataset(\n",
        "    root_dir='./data/testset',\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# ----------------------------------------------\n",
        "# 3. Evaluation Loop\n",
        "# ----------------------------------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():  # Disable gradient calculation during evaluation\n",
        "    for inputs, labels in test_loader:\n",
        "        # Move inputs and labels to the appropriate device\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Get model predictions\n",
        "        outputs = model(inputs)\n",
        "        # Get the predicted class indices\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        # Update total and correct counts\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "# Calculate and print the test accuracy\n",
        "print(f'Test Accuracy: {100 * correct / total:.2f}%')\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}